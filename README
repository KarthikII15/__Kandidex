
## ğŸ“˜ Kandidex â€“ User Manual

---

### 1. ğŸ“Œ Introduction

**Kandidex** is an AI-powered tool for evaluating job candidates. It leverages **LLMs (like LLaMA 3)** locally via **Ollama**, making it cost-efficient and private.

The user uploads two files:

* An **interview transcript** (conversation with the candidate)
* A **problem-solving test** (answers or coding test)

The application:

* Extracts content from the files
* Uses a prompt to evaluate and score the candidate
* Outputs structured feedback and recommendations

 âš ï¸ Caution: The AI-generated evaluation is intended to assist decision-making but should not be treated as the final hiring verdict. Human review is essential before taking any action.

---

### 2. ğŸ—‚ï¸ Project Structure

```plaintext
Kandidex-master/
â”œâ”€â”€ BackEnd/
â”‚   â”œâ”€â”€ app.py                  # Main Flask app with evaluation logic
â”‚   â”œâ”€â”€ uploads/                # Temporary upload storage
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ extract_text.py     # File parsing logic (.txt, .pdf, .docx)
â”‚       â””â”€â”€ llama_prompt.py     # Prompt construction + Ollama API logic
â”œâ”€â”€ FrontEnd/                   # React-based frontend UI
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ components/         # Likely contains form and result views
â”œâ”€â”€ README                      # Setup instructions
```

---

### 3. ğŸ§° System Requirements

#### ğŸ“¦ Backend (Python):

* Python 3.8+
* Flask
* Flask-CORS
* `python-docx`, `PyPDF2` (for text extraction)

#### ğŸŒ Frontend:

* Node.js (v16+)
* NPM

#### ğŸ§  Model:

* Ollama installed
* LLaMA 3 8B model (`llama3:8b`) pulled locally

---

### 4. ğŸ—ï¸ Setup Instructions

#### ğŸ”§ Backend Setup:

1. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```
2. Install Ollama: [https://ollama.com](https://ollama.com)
3. Pull the model:

   ```bash
   ollama pull llama3:8b
   ```
4. Run the backend:

   ```bash
   cd BackEnd
   python app.py
   ```

#### ğŸ’» Frontend Setup:

1. Install dependencies:

   ```bash
   cd FrontEnd
   npm install
   ```
2. Start the development server:

   ```bash
   npm start
   ```

   The UI runs on `http://localhost:3000`

---

### 5. ğŸ“¤ Upload and Evaluation Flow

**UI Fields**:

* Upload Interview Transcript (`transcript`)
* Upload Test Document (`test`)
* Job Role (optional): e.g. "Data Scientist"
* Skills to Rate (optional): Comma-separated string

**Default Skills if Left Blank**:

* Communication Skills
* Technical Knowledge
* Problem Solving

**On Submit**:

* The frontend sends a `POST` request to `/upload` (Flask API)
* Files are stored in `BackEnd/uploads/`
* `extract_text_from_file` parses files (.txt, .pdf, .docx)
* `generate_evaluation` sends formatted text to LLaMA via Ollama
* Response is returned with ratings, summary, and recommendation

---

### 6. âš™ï¸ API Reference

#### ğŸ“ Endpoint: `/upload`

* **Method**: POST
* **Consumes**: `multipart/form-data`
* **Fields**:

  * `transcript`: File (required)
  * `test`: File (required)
  * `job_role`: string (optional)
  * `skills_to_rate`: string (optional)

**Sample Response**:

```json
{
  "summary": "The candidate showed moderate skill in technical concepts...",
  "ratings": {
    "Communication Skills": 3,
    "Technical Knowledge": 4,
    "Problem Solving": 2
  },
  "recommendation": "Not recommended for hire"
}
```
### 7. Output Evaluation Guide 
This section helps interpret the generated evaluation output. Kandidex uses a structured prompt to elicit specific feedback from the LLaMA 3 model, formatted as:

âœ… Candidate Name

ğŸ“ Evaluation Summary

â­ Skill Ratings

âœ… Recommendation

ğŸ“§ Email Draft for HR

### 7.1 ğŸ§  Evaluation Summary
This section captures the narrative understanding of the candidateâ€™s strengths and weaknesses derived from the transcript and test answers.

Interpreting It:

Look for:

Technical insights mentioned

Soft skill behavior (e.g., clarity, adaptability)

Mention of specific project experiences or responses

Helps gauge depth vs breadth of understanding

Usually begins with:

â€œThe candidate demonstrated a strong understanding of â€¦â€

### 7.2 â­ Skill Ratings
This is a quantified view of performance across specified (or default) skill areas. Output looks like:

Skill Ratings:
Communication Skills: 4/5
Technical Knowledge: 3/5
Problem Solving: 5/5
Teamwork: 2/5
â­ Rating Scale:
Rating	Meaning
5/5	Exceptional â€” industry expert level
4/5	Strong â€” well above average
3/5	Average â€” meets expectations
2/5	Below average â€” needs improvement
1/5	Poor â€” lacks fundamental ability
N/A	Skill not clearly addressed in content

ğŸ’¡ Tip: Skills marked low (1 or 2) in core job areas should be red flags.

### 7.3 âœ… Recommendation
This is the final suggestion by the AI model, derived from the full prompt context.

It will be one of the following (or similar):

Hire â€” Candidate is suitable for the role

Consider with Caution â€” Mixed performance, may depend on team or training

Do Not Hire â€” Major skill or behavioral gaps detected

### "âš  Even if a transcript includes â€œHireâ€ â€” manually confirm it aligns with company hiring standards."
---

### 8. ğŸ“‘ Supported File Types

* `.txt` â†’ Plain text
* `.pdf` â†’ Parsed with PyPDF2
* `.docx` â†’ Parsed with python-docx

Files are saved temporarily in `BackEnd/uploads/` and removed manually or via custom script if needed.

---

### 9. ğŸ”„ LLaMA Prompt Logic (Under the Hood)

Prompt is dynamically generated based on:

* Extracted transcript
* Test content
* Job role and selected skills

LLM output is then parsed into:

* Summary
* Score per skill (1 to 5)
* Final hiring recommendation

Prompt example is found in:

```python
utils/llama_prompt.py
```

---

### 10. â— Error Handling

| Situation           | Behavior                               |
| ------------------- | -------------------------------------- |
| Missing files       | Returns 400: `Both files are required` |
| Invalid file format | Returns 500 or parsing fails silently  |
| Ollama not running  | Timeout or empty response from LLM     |
| No skills provided  | Uses default 3 skills                  |

Console logs include:

* Upload status
* File parsing status
* First 100 characters of parsed transcript for debug

âš ï¸ â€œAI results may vary based on transcript/test quality â€” manual validation is recommended.â€
---

### 11. ğŸ› ï¸ Maintenance Tips

* Clean `uploads/` regularly to avoid disk clutter.
* Restart Flask or Ollama server if performance lags.
* Tune `generate_evaluation()` to improve output structure.

---
